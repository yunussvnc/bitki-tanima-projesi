import os
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
import numpy as np

# GPU AyarlarÄ±
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    try:
        # GPU bellek bÃ¼yÃ¼mesini dinamik olarak ayarla
        for gpu in physical_devices:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"GPU bulundu: {len(physical_devices)} adet")
        print("GPU bellek bÃ¼yÃ¼mesi aktif edildi")
    except RuntimeError as e:
        print(f"GPU ayarlarÄ± yapÄ±landÄ±rÄ±lamadÄ±: {e}")
else:
    print("GPU bulunamadÄ±, CPU kullanÄ±lacak")

# Mixed Precision Training
tf.keras.mixed_precision.set_global_policy('mixed_float16')
print("Mixed Precision Training aktif edildi")

# === 1. VERÄ° YOLLARI ===
base_dir = r"C:\Users\eruru\OneDrive\Belgeler\bitki_guncel_proje\data"
train = os.path.join(base_dir, "train")
valid = os.path.join(base_dir, "valid")
test = os.path.join(base_dir, "test")

# === 2. GELÄ°ÅžMÄ°Åž VERÄ° ARTIRMA ===
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    fill_mode='nearest',
    brightness_range=[0.8, 1.2],
    validation_split=0.2,
    rescale=1./255
)

valid_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# === 3. VERÄ° SETLERÄ°NÄ° YÃœKLE ===
train_generator = train_datagen.flow_from_directory(
    train,
    target_size=(224, 224),  # ResNet50 iÃ§in standart boyut
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

validation_generator = valid_datagen.flow_from_directory(
    train,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# === 4. RESNET50 TABANLI MODEL MÄ°MARÄ°SÄ° ===
base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

# Transfer learning iÃ§in base model'i dondur
base_model.trainable = False

# Model mimarisi
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# === 5. MODEL DERLEME ===
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# === 6. CALLBACKS ===
callbacks = [
    EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=5,
        min_lr=1e-6
    ),
    ModelCheckpoint(
        'models/bitki_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max'
    )
]

# === 7. Ä°LK EÄžÄ°TÄ°M AÅžAMASI ===
print("\nðŸš€ Ä°lk eÄŸitim aÅŸamasÄ± baÅŸlÄ±yor...")
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    callbacks=callbacks
)

# === 8. FINE-TUNING AÅžAMASI ===
# Son birkaÃ§ katmanÄ± Ã§Ã¶z
base_model.trainable = True
for layer in base_model.layers[:-30]:
    layer.trainable = False

# Modeli dÃ¼ÅŸÃ¼k learning rate ile tekrar derle
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\nðŸš€ Fine-tuning aÅŸamasÄ± baÅŸlÄ±yor...")
history_fine = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    callbacks=callbacks
)

# === 9. MODEL KAYDETME ===
model.save('models/bitki_model.h5')

# SÄ±nÄ±f isimlerini kaydet
class_names = list(train_generator.class_indices.keys())
with open('models/class_names.txt', 'w') as f:
    f.write('\n'.join(class_names))

print("\nâœ… Model eÄŸitimi tamamlandÄ± ve kaydedildi!")
